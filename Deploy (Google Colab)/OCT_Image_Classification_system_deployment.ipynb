{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# Colab: Wireframe OCT Classifier (Simple UI + Grad-CAM)\n",
        "# ================================================\n",
        "\n",
        "# ---------- 0) Install deps ----------\n",
        "!pip -q install streamlit==1.37.1 pillow numpy pandas timm pyngrok \\\n",
        "  opencv-python-headless==4.10.0.84 \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "# Torch (CU121 wheels)\n",
        "!pip -q install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# ---------- 1) Drive mount ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- 2) CONFIG ----------\n",
        "WEIGHTS_DRIVE_PATH = \"/content/drive/MyDrive/Edu/My ICBT/TOPUP/RESEARCH/resnet18_oct2017_final_weights.pth\"\n",
        "NGROK_AUTH_TOKEN   = \"30W6skuqZhzyrPnVSLr2EsiTBbf_5t8t1gHHNR7CSNczLzCDy\"\n",
        "\n",
        "# ---------- 3) Project folder ----------\n",
        "import os, shutil, time, subprocess\n",
        "APP_DIR = \"/content/app\"\n",
        "os.makedirs(APP_DIR, exist_ok=True)\n",
        "%cd $APP_DIR\n",
        "\n",
        "# Copy weights if found\n",
        "dst_ckpt = os.path.join(APP_DIR, \"resnet18_oct2017_final_weights.pth\")\n",
        "if os.path.exists(WEIGHTS_DRIVE_PATH):\n",
        "    shutil.copy2(WEIGHTS_DRIVE_PATH, dst_ckpt)\n",
        "    print(f\"[OK] Copied weights -> {dst_ckpt}\")\n",
        "else:\n",
        "    print(f\"[WARN] Weights not found at: {WEIGHTS_DRIVE_PATH}\")\n",
        "    print(\"      Update WEIGHTS_DRIVE_PATH above and rerun if needed.\")\n",
        "\n",
        "# ---------- 4) predictor.py ----------\n",
        "from pathlib import Path\n",
        "Path(\"predictor.py\").write_text(r\"\"\"# predictor.py\n",
        "import io, pickle\n",
        "from typing import List, Dict, Optional\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import timm  # for DeiT / ViTs\n",
        "\n",
        "class PadAndResize:\n",
        "    def __init__(self, target_size=224, fill_color=(0,0,0)):\n",
        "        self.target_size = target_size\n",
        "        self.fill_color = fill_color\n",
        "    def __call__(self, img: Image.Image):\n",
        "        w, h = img.size\n",
        "        max_side = max(w, h)\n",
        "        canvas = Image.new(\"RGB\", (max_side, max_side), self.fill_color)\n",
        "        canvas.paste(img, ((max_side - w)//2, (max_side - h)//2))\n",
        "        try:\n",
        "            resample = Image.Resampling.BILINEAR\n",
        "        except AttributeError:\n",
        "            resample = Image.BILINEAR\n",
        "        return canvas.resize((self.target_size, self.target_size), resample)\n",
        "\n",
        "DEFAULT_CLASSES = [\"CNV\", \"DME\", \"DRUSEN\", \"NORMAL\"]\n",
        "\n",
        "def _build_model(model_name: str, num_classes: int) -> nn.Module:\n",
        "    if model_name == \"resnet18\":\n",
        "        m = models.resnet18(weights=None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    elif model_name == \"resnet50\":\n",
        "        m = models.resnet50(weights=None)\n",
        "        m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
        "    elif model_name == \"convnext_tiny\":\n",
        "        m = models.convnext_tiny(weights=None)\n",
        "        m.classifier[-1] = nn.Linear(m.classifier[-1].in_features, num_classes)\n",
        "    elif model_name == \"deit_small_distilled_patch16_224\":\n",
        "        m = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
        "    return m\n",
        "\n",
        "def _is_state_dict_like(obj: dict) -> bool:\n",
        "    if not isinstance(obj, dict):\n",
        "        return False\n",
        "    if \"state_dict\" in obj: return True\n",
        "    if \"model\" in obj and isinstance(obj[\"model\"], dict): return True\n",
        "    return any((\"weight\" in k) or (\"bias\" in k) for k in list(obj.keys()))\n",
        "\n",
        "def _safe_load_any(path: str):\n",
        "    try:\n",
        "        return torch.load(path, map_location=\"cpu\")\n",
        "    except Exception:\n",
        "        with open(path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "def _normalize_state_dict(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        if \"state_dict\" in obj and isinstance(obj[\"state_dict\"], dict):\n",
        "            sd = obj[\"state_dict\"]\n",
        "        elif \"model\" in obj and isinstance(obj[\"model\"], dict):\n",
        "            sd = obj[\"model\"]\n",
        "        else:\n",
        "            sd = obj\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported checkpoint format\")\n",
        "    def strip_prefix(d, pfx):\n",
        "        if any(k.startswith(pfx) for k in d.keys()):\n",
        "            return {k[len(pfx):]: v for k, v in d.items()}\n",
        "        return d\n",
        "    sd = strip_prefix(sd, \"_orig_mod.\")\n",
        "    sd = strip_prefix(sd, \"module.\")\n",
        "    sd = strip_prefix(sd, \"model.\")\n",
        "    return sd\n",
        "\n",
        "def load_model(ckpt_path: str,\n",
        "               fallback_model_name: str = \"resnet18\",\n",
        "               fallback_classes: Optional[List[str]] = None,\n",
        "               img_size: int = 224):\n",
        "    blob = _safe_load_any(ckpt_path)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    mean = [0.485, 0.456, 0.406]; std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    if isinstance(blob, dict) and \"state_dict\" in blob and \"model_name\" in blob:\n",
        "        model_name = blob[\"model_name\"]\n",
        "        class_names = blob.get(\"class_names\", fallback_classes or DEFAULT_CLASSES)\n",
        "        img_size = int(blob.get(\"img_size\", img_size))\n",
        "        mean = blob.get(\"normalize_mean\", mean); std  = blob.get(\"normalize_std\",  std)\n",
        "        state_dict = _normalize_state_dict(blob)\n",
        "    elif isinstance(blob, dict) and _is_state_dict_like(blob):\n",
        "        model_name = fallback_model_name\n",
        "        class_names = fallback_classes or DEFAULT_CLASSES\n",
        "        state_dict = _normalize_state_dict(blob)\n",
        "    else:\n",
        "        model_name = fallback_model_name\n",
        "        class_names = fallback_classes or DEFAULT_CLASSES\n",
        "        state_dict = blob\n",
        "\n",
        "    model = _build_model(model_name, num_classes=len(class_names))\n",
        "    try:\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "    except RuntimeError:\n",
        "        changed = False\n",
        "        if hasattr(model, \"head\") and isinstance(model.head, nn.Linear):\n",
        "            if model.head.out_features != len(class_names):\n",
        "                model.head = nn.Linear(model.head.in_features, len(class_names)); changed = True\n",
        "        if hasattr(model, \"head_dist\") and isinstance(model.head_dist, nn.Linear):\n",
        "            if model.head_dist.out_features != len(class_names):\n",
        "                model.head_dist = nn.Linear(model.head_dist.in_features, len(class_names)); changed = True\n",
        "        model.load_state_dict(state_dict, strict=False if changed else False)\n",
        "\n",
        "    model.to(device).eval()\n",
        "    preprocess = T.Compose([\n",
        "        PadAndResize(target_size=img_size, fill_color=(0,0,0)),\n",
        "        T.Grayscale(num_output_channels=3),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=mean, std=std),\n",
        "    ])\n",
        "    return model, preprocess, class_names, device, img_size, model_name\n",
        "\n",
        "@torch.inference_mode()\n",
        "def predict_image_bytes(model, preprocess, class_names, device, img_bytes: bytes) -> Dict:\n",
        "    img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "    x = preprocess(img).unsqueeze(0).to(device)\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy().tolist()\n",
        "    best_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    return {\"pred_label\": class_names[best_idx],\n",
        "            \"pred_idx\": best_idx,\n",
        "            \"probs\": {cls: float(probs[i]) for i, cls in enumerate(class_names)}}\n",
        "\n",
        "def _resolve_target_layer(model: nn.Module, model_name: str):\n",
        "    if model_name == \"resnet18\":\n",
        "        return getattr(model.layer4[-1], \"conv2\", model.layer4[-1])\n",
        "    if model_name == \"resnet50\":\n",
        "        return getattr(model.layer4[-1], \"conv3\", model.layer4[-1])\n",
        "    if model_name == \"convnext_tiny\":\n",
        "        try: return model.features[6][-1].dwconv\n",
        "        except Exception: return model.features[6]\n",
        "    return None\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model: nn.Module, target_layer: nn.Module):\n",
        "        self.model = model; self.target_layer = target_layer\n",
        "        self._activations = None; self._gradients = None\n",
        "        self._fwd_handle = self.target_layer.register_forward_hook(self._forward_hook)\n",
        "        self._bwd_handle = self.target_layer.register_full_backward_hook(self._backward_hook)\n",
        "    def _forward_hook(self, module, inp, out): self._activations = out.clone()\n",
        "    def _backward_hook(self, module, grad_in, grad_out): self._gradients = grad_out[0]\n",
        "    def remove(self): self._fwd_handle.remove(); self._bwd_handle.remove()\n",
        "    def __call__(self, input_tensor: torch.Tensor, class_idx: Optional[int] = None):\n",
        "        self.model.zero_grad(set_to_none=True)\n",
        "        with torch.inference_mode(False), torch.enable_grad():\n",
        "            x = input_tensor.clone().detach().requires_grad_(True)\n",
        "            logits = self.model(x)\n",
        "        if class_idx is None: class_idx = int(torch.argmax(logits, dim=1).item())\n",
        "        one_hot = torch.zeros_like(logits); one_hot[0, class_idx] = 1.0\n",
        "        with torch.inference_mode(False): logits.backward(gradient=one_hot)\n",
        "        A = self._activations; dA = self._gradients\n",
        "        if A is None or dA is None: raise RuntimeError(\"Grad-CAM hooks failed.\")\n",
        "        weights = dA.mean(dim=(2,3), keepdim=True)\n",
        "        cam = (weights * A).sum(dim=1).relu().squeeze(0)\n",
        "        cam -= cam.min(); cam = cam / (cam.max() + 1e-8)\n",
        "        return cam.detach().cpu().numpy(), class_idx, logits.detach()\n",
        "\n",
        "def _apply_colormap_on_image(pil_img: Image.Image, cam: np.ndarray, alpha: float=0.35):\n",
        "    img = np.array(pil_img.convert(\"RGB\")); H, W = img.shape[:2]\n",
        "    cam_resized = cv2.resize(cam, (W, H))\n",
        "    heat = np.uint8(255 * cam_resized); heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n",
        "    base = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    over = cv2.addWeighted(heat, alpha, base, 1 - alpha, 0)\n",
        "    return Image.fromarray(cv2.cvtColor(over, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "def gradcam_image_bytes(model, preprocess, device, model_name, img_bytes, target_class, img_size, alpha=0.35):\n",
        "    target_layer = _resolve_target_layer(model, model_name)\n",
        "    if target_layer is None:\n",
        "        raise NotImplementedError(\"Grad-CAM only for CNN backbones (ResNet/ConvNeXt).\")\n",
        "    pil = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "    x = preprocess(pil).unsqueeze(0).to(device)\n",
        "    cam_obj = GradCAM(model, target_layer)\n",
        "    with torch.inference_mode(False), torch.enable_grad():\n",
        "        logits = model(x)\n",
        "    pred_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    class_idx = target_class if target_class is not None else pred_idx\n",
        "    cam_map, used_idx, _ = cam_obj(x, class_idx=class_idx)\n",
        "    cam_obj.remove()\n",
        "    base = PadAndResize(target_size=img_size, fill_color=(0,0,0))(pil)\n",
        "    overlay = _apply_colormap_on_image(base, cam_map, alpha=alpha)\n",
        "    probs = torch.softmax(logits, dim=1).squeeze(0).detach().cpu().numpy().tolist()\n",
        "    return overlay, used_idx, probs\n",
        "\"\"\", encoding=\"utf-8\")\n",
        "\n",
        "# ---------- 5) app.py (simple wireframe UI; no preset/preset radio/CSV) ----------\n",
        "Path(\"app.py\").write_text(r\"\"\"# app.py ‚Äî simple wireframe UI\n",
        "import json, pandas as pd, streamlit as st\n",
        "from predictor import load_model, predict_image_bytes, gradcam_image_bytes, DEFAULT_CLASSES\n",
        "\n",
        "st.set_page_config(page_title=\"Retinal OCT Classifier\", page_icon=\"üëÅÔ∏è\", layout=\"wide\")\n",
        "\n",
        "WIREFRAME_CSS = '''\n",
        "<style>\n",
        ".block-container { padding-top: 1.25rem; padding-bottom: 1rem; }\n",
        ".w-card { border: 2px solid #1f1f1f20; border-radius: 8px; padding: 16px 18px; background: #fafafa; }\n",
        ".w-title { font-weight: 700; margin-bottom: 6px; }\n",
        ".w-subtle { color: #666; font-size: 0.9rem; }\n",
        ".stButton>button, .stDownloadButton>button { border: 1px solid #33333355; background: #e9e9e9; color: #111; border-radius: 8px; }\n",
        "section[data-testid=\"stSidebar\"] .stSelectbox,\n",
        "section[data-testid=\"stSidebar\"] .stTextInput,\n",
        "section[data-testid=\"stSidebar\"] .stNumberInput,\n",
        "section[data-testid=\"stSidebar\"] .stCheckbox,\n",
        "section[data-testid=\"stSidebar\"] .stSlider { border-bottom: 1px solid #cfcfcf; padding-bottom: .35rem; margin-bottom: .65rem; }\n",
        "</style>\n",
        "'''\n",
        "st.markdown(WIREFRAME_CSS, unsafe_allow_html=True)\n",
        "\n",
        "st.title(\"Retinal OCT Classifier\")\n",
        "st.caption(\"CNV ¬∑ DME ¬∑ DRUSEN ¬∑ NORMAL | padded-resize input | Grad-CAM for CNN backbones\")\n",
        "\n",
        "# ----- Sidebar: minimal controls -----\n",
        "with st.sidebar:\n",
        "    st.header(\"Model Options\")\n",
        "    backbone = st.selectbox(\"Backbone\", [\"resnet18\", \"deit_small_distilled_patch16_224\"], index=0)\n",
        "    ckpt_path = st.text_input(\"Checkpoint path\", \"resnet18_oct2017_final_weights.pth\")\n",
        "    img_size = st.number_input(\"Image size (px)\", min_value=128, max_value=1024, value=224, step=32)\n",
        "    st.subheader(\"Grad-CAM\")\n",
        "    show_cam = st.checkbox(\"Show Grad-CAM\", value=True)\n",
        "    cam_alpha = st.slider(\"Heatmap strength\", 0.1, 0.9, 0.35, 0.05)\n",
        "\n",
        "if not ckpt_path:\n",
        "    st.warning(\"Provide a checkpoint path in the sidebar.\")\n",
        "    st.stop()\n",
        "\n",
        "try:\n",
        "    model, preprocess, class_names, device, real_imgsz, real_modelname = load_model(\n",
        "        ckpt_path, fallback_model_name=backbone, fallback_classes=DEFAULT_CLASSES, img_size=int(img_size)\n",
        "    )\n",
        "    st.success(f\"Loaded {real_modelname} on {device} ¬∑ classes: {', '.join(class_names)} ¬∑ image {real_imgsz}px\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Load error: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# ----- Upload card -----\n",
        "st.markdown('<div class=\"w-card\">', unsafe_allow_html=True)\n",
        "st.markdown('<div class=\"w-title\">Upload OCT Image</div><div class=\"w-subtle\">Drag & drop file here or use Browse</div>', unsafe_allow_html=True)\n",
        "up = st.file_uploader(\"\", type=[\"png\",\"jpg\",\"jpeg\",\"tif\",\"bmp\"])\n",
        "st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "if up is None:\n",
        "    st.info(\"Tip: toggle Grad-CAM in the sidebar. Anonymize patient data before upload.\")\n",
        "    st.stop()\n",
        "\n",
        "raw = up.read()\n",
        "\n",
        "# ----- Middle row: Original + Grad-CAM -----\n",
        "c1, c2 = st.columns([1,1], gap=\"large\")\n",
        "with c1:\n",
        "    st.markdown('<div class=\"w-card\"><div class=\"w-title\">Original OCT</div><div class=\"w-subtle\">uploaded OCT image</div>', unsafe_allow_html=True)\n",
        "    st.image(up, use_column_width=True)\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "with c2:\n",
        "    st.markdown('<div class=\"w-card\"><div class=\"w-title\">Grad-CAM Heatmap</div><div class=\"w-subtle\">red = higher importance</div>', unsafe_allow_html=True)\n",
        "    if show_cam:\n",
        "        try:\n",
        "            overlay, used_idx, _ = gradcam_image_bytes(model, preprocess, device, real_modelname, raw,\n",
        "                                                       target_class=None, img_size=real_imgsz, alpha=cam_alpha)\n",
        "            st.image(overlay, use_column_width=True)\n",
        "        except NotImplementedError as e:\n",
        "            st.info(f\"{e}  Switch to a CNN (e.g., ResNet18) to view Grad-CAM.\")\n",
        "        except Exception as e:\n",
        "            st.warning(f\"Grad-CAM failed: {e}\")\n",
        "    else:\n",
        "        st.caption(\"Grad-CAM disabled\")\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "# ----- Bottom row: Prediction + Probabilities -----\n",
        "p1, p2 = st.columns([1,1], gap=\"large\")\n",
        "with p1:\n",
        "    st.markdown('<div class=\"w-card\"><div class=\"w-title\">Prediction</div><div class=\"w-subtle\">Top-1 class and confidence</div>', unsafe_allow_html=True)\n",
        "    try:\n",
        "        out = predict_image_bytes(model, preprocess, class_names, device, raw)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Prediction error: {e}\")\n",
        "        st.stop()\n",
        "    pred_label = out[\"pred_label\"]; conf = float(out[\"probs\"].get(pred_label, 0.0))\n",
        "    st.subheader(f\"Predicted class: {pred_label}\")\n",
        "    st.write(f\"Confidence: {conf:.2f}\")\n",
        "    st.download_button(\"Download results\",\n",
        "                       data=json.dumps({\"prediction\": pred_label, \"confidence\": conf, \"probs\": out[\"probs\"]}, indent=2),\n",
        "                       file_name=\"oct_prediction.json\", mime=\"application/json\")\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "with p2:\n",
        "    st.markdown('<div class=\"w-card\"><div class=\"w-title\">Class Probabilities</div>', unsafe_allow_html=True)\n",
        "    df = pd.DataFrame({\"Class\": list(out[\"probs\"].keys()),\n",
        "                       \"Probability\": [float(v) for v in out[\"probs\"].values()]}) \\\n",
        "         .sort_values(\"Class\").reset_index(drop=True)\n",
        "    st.dataframe(df, use_container_width=True, hide_index=True)\n",
        "    st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\"\"\", encoding=\"utf-8\")\n",
        "\n",
        "print(\"Files:\", os.listdir(APP_DIR))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEADQbfcLRoP",
        "outputId": "ff4274ca-6d83-4330-ffa8-3338fa932907"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/app\n",
            "[OK] Copied weights -> /content/app/resnet18_oct2017_final_weights.pth\n",
            "Files: ['predictor.py', '__pycache__', 'app.py', 'resnet18_oct2017_final_weights.pth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 6) Run Streamlit with ngrok (single-session, cleaned) ----------\n",
        "import subprocess, time, os, signal\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# 1) Hard kill any leftover ngrok/Streamlit processes in this runtime\n",
        "!pkill -f \"ngrok\" || true\n",
        "!pkill -f \"streamlit run app.py\" || true\n",
        "\n",
        "# 2) Double-check with pyngrok API and close any existing tunnels\n",
        "try:\n",
        "    for t in ngrok.get_tunnels():\n",
        "        try:\n",
        "            ngrok.disconnect(t.public_url)\n",
        "        except Exception:\n",
        "            pass\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 3) Your token (single agent only)\n",
        "NGROK_AUTH_TOKEN = \"30W6skuqZhzyrPnVSLr2EsiTBbf_5t8t1gHHNR7CSNczLzCDy\"\n",
        "!ngrok config add-authtoken \"$NGROK_AUTH_TOKEN\"\n",
        "\n",
        "# 4) Start Streamlit server\n",
        "server = subprocess.Popen(\n",
        "    [\n",
        "        \"streamlit\", \"run\", \"app.py\",\n",
        "        \"--server.port\", \"8501\",\n",
        "        \"--server.address\", \"0.0.0.0\",\n",
        "        \"--server.headless\", \"true\",\n",
        "    ],\n",
        "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n",
        ")\n",
        "\n",
        "# 5) Give Streamlit a moment to boot\n",
        "time.sleep(5)\n",
        "\n",
        "# 6) Open ONE public tunnel (HTTP)\n",
        "public_tunnel = ngrok.connect(8501, \"http\")\n",
        "print(\"üîó Public URL:\", public_tunnel.public_url)\n",
        "print(\"----- STREAMLIT LOGS -----\")\n",
        "try:\n",
        "    for line in server.stdout:\n",
        "        if line is None:\n",
        "            break\n",
        "        print(line, end=\"\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n[Interrupted]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H2GMX7VLv4f",
        "outputId": "4b68168b-2b85-40fa-eab9-0c932d510621"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "üîó Public URL: https://0df02015ddfe.ngrok-free.app\n",
            "----- STREAMLIT LOGS -----\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  URL: http://0.0.0.0:8501\n",
            "\n",
            "2025-09-06 18:17:35.059 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:17:35.471 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-09-06 18:17:42.174 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:17:42.921 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-09-06 18:18:37.000 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:42.394 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:44.874 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:46.399 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:47.236 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:58.177 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 18:18:59.234 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 19:46:46.514 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 20:34:56.678 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 20:35:43.824 Session with id a2e6d0f3-0093-442a-a4a2-a55ab1c270c7 is already connected! Connecting to a new session.\n",
            "2025-09-06 20:35:44.335 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 20:35:44.749 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-09-06 22:01:27.811 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:06:47.912 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:08:26.876 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:08:27.891 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-09-06 22:08:34.828 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:08:43.902 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:08:53.066 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:09:01.783 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:09:08.437 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:11:48.136 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:13:50.592 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-09-06 22:13:51.013 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-09-06 22:14:03.015 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "\n",
            "[Interrupted]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}